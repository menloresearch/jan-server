// Package docs Code generated by swaggo/swag. DO NOT EDIT
package docs

import "github.com/swaggo/swag"

const docTemplate = `{
    "schemes": {{ marshal .Schemes }},
    "swagger": "2.0",
    "info": {
        "description": "{{escape .Description}}",
        "title": "{{.Title}}",
        "contact": {},
        "version": "{{.Version}}"
    },
    "host": "{{.Host}}",
    "basePath": "{{.BasePath}}",
    "paths": {
        "/v1/chat/completion": {
            "post": {
                "security": [
                    {
                        "BearerAuth": []
                    }
                ],
                "description": "Generates a model response for the given chat conversation.",
                "consumes": [
                    "application/json"
                ],
                "produces": [
                    "application/json"
                ],
                "tags": [
                    "Chat"
                ],
                "summary": "Create a chat completion",
                "parameters": [
                    {
                        "description": "Chat completion request payload",
                        "name": "request",
                        "in": "body",
                        "required": true,
                        "schema": {
                            "$ref": "#/definitions/openai.ChatCompletionRequest"
                        }
                    }
                ],
                "responses": {
                    "200": {
                        "description": "Successful response",
                        "schema": {
                            "$ref": "#/definitions/app_interfaces_http_routes_v1_chat.ChatCompletionResponseSwagger"
                        }
                    },
                    "400": {
                        "description": "Invalid request payload",
                        "schema": {
                            "$ref": "#/definitions/menlo_ai_jan-api-gateway_app_interfaces_http_responses.ErrorResponse"
                        }
                    },
                    "401": {
                        "description": "Unauthorized",
                        "schema": {
                            "$ref": "#/definitions/menlo_ai_jan-api-gateway_app_interfaces_http_responses.ErrorResponse"
                        }
                    },
                    "500": {
                        "description": "Internal server error",
                        "schema": {
                            "$ref": "#/definitions/menlo_ai_jan-api-gateway_app_interfaces_http_responses.ErrorResponse"
                        }
                    }
                }
            }
        },
        "/v1/mcp": {
            "post": {
                "security": [
                    {
                        "BearerAuth": []
                    }
                ],
                "description": "Handles Model Context Protocol (MCP) requests over an HTTP stream. The response is sent as a continuous stream of data.",
                "consumes": [
                    "application/json"
                ],
                "produces": [
                    "text/event-stream"
                ],
                "tags": [
                    "MCP"
                ],
                "summary": "MCP streamable endpoint",
                "parameters": [
                    {
                        "description": "MCP request payload",
                        "name": "request",
                        "in": "body",
                        "required": true,
                        "schema": {}
                    }
                ],
                "responses": {
                    "200": {
                        "description": "Streamed response (SSE or chunked transfer)",
                        "schema": {
                            "type": "string"
                        }
                    }
                }
            }
        },
        "/v1/models": {
            "get": {
                "security": [
                    {
                        "BearerAuth": []
                    }
                ],
                "description": "Retrieves a list of available models that can be used for chat completions or other tasks.",
                "consumes": [
                    "application/json"
                ],
                "produces": [
                    "application/json"
                ],
                "tags": [
                    "Models"
                ],
                "summary": "List available models",
                "responses": {
                    "200": {
                        "description": "Successful response",
                        "schema": {
                            "$ref": "#/definitions/app_interfaces_http_routes_v1.ModelsResponse"
                        }
                    }
                }
            }
        },
        "/v1/version": {
            "get": {
                "description": "Returns the current build version of the API server.",
                "produces": [
                    "application/json"
                ],
                "tags": [
                    "system"
                ],
                "summary": "Get API build version",
                "responses": {
                    "200": {
                        "description": "version info",
                        "schema": {
                            "type": "object",
                            "additionalProperties": {
                                "type": "string"
                            }
                        }
                    }
                }
            }
        }
    },
    "definitions": {
        "app_interfaces_http_routes_v1.Model": {
            "type": "object",
            "properties": {
                "created": {
                    "type": "integer"
                },
                "id": {
                    "type": "string"
                },
                "object": {
                    "type": "string"
                },
                "owned_by": {
                    "type": "string"
                }
            }
        },
        "app_interfaces_http_routes_v1.ModelsResponse": {
            "type": "object",
            "properties": {
                "data": {
                    "type": "array",
                    "items": {
                        "$ref": "#/definitions/app_interfaces_http_routes_v1.Model"
                    }
                },
                "object": {
                    "type": "string"
                }
            }
        },
        "app_interfaces_http_routes_v1_chat.ChatCompletionResponseSwagger": {
            "type": "object",
            "properties": {
                "choices": {
                    "type": "array",
                    "items": {
                        "$ref": "#/definitions/openai.ChatCompletionChoice"
                    }
                },
                "created": {
                    "type": "integer"
                },
                "id": {
                    "type": "string"
                },
                "model": {
                    "type": "string"
                },
                "object": {
                    "type": "string"
                },
                "usage": {
                    "$ref": "#/definitions/openai.Usage"
                }
            }
        },
        "menlo_ai_jan-api-gateway_app_interfaces_http_responses.ErrorResponse": {
            "type": "object",
            "properties": {
                "code": {
                    "type": "string"
                },
                "error": {
                    "type": "string"
                }
            }
        },
        "openai.ChatCompletionChoice": {
            "type": "object",
            "properties": {
                "content_filter_results": {
                    "$ref": "#/definitions/openai.ContentFilterResults"
                },
                "finish_reason": {
                    "description": "FinishReason\nstop: API returned complete message,\nor a message terminated by one of the stop sequences provided via the stop parameter\nlength: Incomplete model output due to max_tokens parameter or token limit\nfunction_call: The model decided to call a function\ncontent_filter: Omitted content due to a flag from our content filters\nnull: API response still in progress or incomplete",
                    "allOf": [
                        {
                            "$ref": "#/definitions/openai.FinishReason"
                        }
                    ]
                },
                "index": {
                    "type": "integer"
                },
                "logprobs": {
                    "$ref": "#/definitions/openai.LogProbs"
                },
                "message": {
                    "$ref": "#/definitions/openai.ChatCompletionMessage"
                }
            }
        },
        "openai.ChatCompletionMessage": {
            "type": "object",
            "properties": {
                "content": {
                    "type": "string"
                },
                "function_call": {
                    "$ref": "#/definitions/openai.FunctionCall"
                },
                "multiContent": {
                    "type": "array",
                    "items": {
                        "$ref": "#/definitions/openai.ChatMessagePart"
                    }
                },
                "name": {
                    "description": "This property isn't in the official documentation, but it's in\nthe documentation for the official library for python:\n- https://github.com/openai/openai-python/blob/main/chatml.md\n- https://github.com/openai/openai-cookbook/blob/main/examples/How_to_count_tokens_with_tiktoken.ipynb",
                    "type": "string"
                },
                "reasoning_content": {
                    "description": "This property is used for the \"reasoning\" feature supported by deepseek-reasoner\nwhich is not in the official documentation.\nthe doc from deepseek:\n- https://api-docs.deepseek.com/api/create-chat-completion#responses",
                    "type": "string"
                },
                "refusal": {
                    "type": "string"
                },
                "role": {
                    "type": "string"
                },
                "tool_call_id": {
                    "description": "For Role=tool prompts this should be set to the ID given in the assistant's prior request to call a tool.",
                    "type": "string"
                },
                "tool_calls": {
                    "description": "For Role=assistant prompts this may be set to the tool calls generated by the model, such as function calls.",
                    "type": "array",
                    "items": {
                        "$ref": "#/definitions/openai.ToolCall"
                    }
                }
            }
        },
        "openai.ChatCompletionRequest": {
            "type": "object",
            "properties": {
                "chat_template_kwargs": {
                    "description": "ChatTemplateKwargs provides a way to add non-standard parameters to the request body.\nAdditional kwargs to pass to the template renderer. Will be accessible by the chat template.\nSuch as think mode for qwen3. \"chat_template_kwargs\": {\"enable_thinking\": false}\nhttps://qwen.readthedocs.io/en/latest/deployment/vllm.html#thinking-non-thinking-modes",
                    "type": "object",
                    "additionalProperties": {}
                },
                "frequency_penalty": {
                    "type": "number"
                },
                "function_call": {
                    "description": "Deprecated: use ToolChoice instead."
                },
                "functions": {
                    "description": "Deprecated: use Tools instead.",
                    "type": "array",
                    "items": {
                        "$ref": "#/definitions/openai.FunctionDefinition"
                    }
                },
                "guided_choice": {
                    "description": "GuidedChoice is a vLLM-specific extension that restricts the model's output\nto one of the predefined string choices provided in this field. This feature\nis used to constrain the model's responses to a controlled set of options,\nensuring predictable and consistent outputs in scenarios where specific\nchoices are required.",
                    "type": "array",
                    "items": {
                        "type": "string"
                    }
                },
                "logit_bias": {
                    "description": "LogitBias is must be a token id string (specified by their token ID in the tokenizer), not a word string.\nincorrect: ` + "`" + `\"logit_bias\":{\"You\": 6}` + "`" + `, correct: ` + "`" + `\"logit_bias\":{\"1639\": 6}` + "`" + `\nrefs: https://platform.openai.com/docs/api-reference/chat/create#chat/create-logit_bias",
                    "type": "object",
                    "additionalProperties": {
                        "type": "integer"
                    }
                },
                "logprobs": {
                    "description": "LogProbs indicates whether to return log probabilities of the output tokens or not.\nIf true, returns the log probabilities of each output token returned in the content of message.\nThis option is currently not available on the gpt-4-vision-preview model.",
                    "type": "boolean"
                },
                "max_completion_tokens": {
                    "description": "MaxCompletionTokens An upper bound for the number of tokens that can be generated for a completion,\nincluding visible output tokens and reasoning tokens https://platform.openai.com/docs/guides/reasoning",
                    "type": "integer"
                },
                "max_tokens": {
                    "description": "MaxTokens The maximum number of tokens that can be generated in the chat completion.\nThis value can be used to control costs for text generated via API.\nDeprecated: use MaxCompletionTokens. Not compatible with o1-series models.\nrefs: https://platform.openai.com/docs/api-reference/chat/create#chat-create-max_tokens",
                    "type": "integer"
                },
                "messages": {
                    "type": "array",
                    "items": {
                        "$ref": "#/definitions/openai.ChatCompletionMessage"
                    }
                },
                "metadata": {
                    "description": "Metadata to store with the completion.",
                    "type": "object",
                    "additionalProperties": {
                        "type": "string"
                    }
                },
                "model": {
                    "type": "string"
                },
                "n": {
                    "type": "integer"
                },
                "parallel_tool_calls": {
                    "description": "Disable the default behavior of parallel tool calls by setting it: false."
                },
                "prediction": {
                    "description": "Configuration for a predicted output.",
                    "allOf": [
                        {
                            "$ref": "#/definitions/openai.Prediction"
                        }
                    ]
                },
                "presence_penalty": {
                    "type": "number"
                },
                "reasoning_effort": {
                    "description": "Controls effort on reasoning for reasoning models. It can be set to \"low\", \"medium\", or \"high\".",
                    "type": "string"
                },
                "response_format": {
                    "$ref": "#/definitions/openai.ChatCompletionResponseFormat"
                },
                "safety_identifier": {
                    "description": "A stable identifier used to help detect users of your application that may be violating OpenAI's usage policies.\nThe IDs should be a string that uniquely identifies each user.\nWe recommend hashing their username or email address, in order to avoid sending us any identifying information.\nhttps://platform.openai.com/docs/api-reference/chat/create#chat_create-safety_identifier",
                    "type": "string"
                },
                "seed": {
                    "type": "integer"
                },
                "service_tier": {
                    "description": "Specifies the latency tier to use for processing the request.",
                    "allOf": [
                        {
                            "$ref": "#/definitions/openai.ServiceTier"
                        }
                    ]
                },
                "stop": {
                    "type": "array",
                    "items": {
                        "type": "string"
                    }
                },
                "store": {
                    "description": "Store can be set to true to store the output of this completion request for use in distillations and evals.\nhttps://platform.openai.com/docs/api-reference/chat/create#chat-create-store",
                    "type": "boolean"
                },
                "stream": {
                    "type": "boolean"
                },
                "stream_options": {
                    "description": "Options for streaming response. Only set this when you set stream: true.",
                    "allOf": [
                        {
                            "$ref": "#/definitions/openai.StreamOptions"
                        }
                    ]
                },
                "temperature": {
                    "type": "number"
                },
                "tool_choice": {
                    "description": "This can be either a string or an ToolChoice object."
                },
                "tools": {
                    "type": "array",
                    "items": {
                        "$ref": "#/definitions/openai.Tool"
                    }
                },
                "top_logprobs": {
                    "description": "TopLogProbs is an integer between 0 and 5 specifying the number of most likely tokens to return at each\ntoken position, each with an associated log probability.\nlogprobs must be set to true if this parameter is used.",
                    "type": "integer"
                },
                "top_p": {
                    "type": "number"
                },
                "user": {
                    "type": "string"
                }
            }
        },
        "openai.ChatCompletionResponseFormat": {
            "type": "object",
            "properties": {
                "json_schema": {
                    "$ref": "#/definitions/openai.ChatCompletionResponseFormatJSONSchema"
                },
                "type": {
                    "$ref": "#/definitions/openai.ChatCompletionResponseFormatType"
                }
            }
        },
        "openai.ChatCompletionResponseFormatJSONSchema": {
            "type": "object",
            "properties": {
                "description": {
                    "type": "string"
                },
                "name": {
                    "type": "string"
                },
                "schema": {},
                "strict": {
                    "type": "boolean"
                }
            }
        },
        "openai.ChatCompletionResponseFormatType": {
            "type": "string",
            "enum": [
                "json_object",
                "json_schema",
                "text"
            ],
            "x-enum-varnames": [
                "ChatCompletionResponseFormatTypeJSONObject",
                "ChatCompletionResponseFormatTypeJSONSchema",
                "ChatCompletionResponseFormatTypeText"
            ]
        },
        "openai.ChatMessageImageURL": {
            "type": "object",
            "properties": {
                "detail": {
                    "$ref": "#/definitions/openai.ImageURLDetail"
                },
                "url": {
                    "type": "string"
                }
            }
        },
        "openai.ChatMessagePart": {
            "type": "object",
            "properties": {
                "image_url": {
                    "$ref": "#/definitions/openai.ChatMessageImageURL"
                },
                "text": {
                    "type": "string"
                },
                "type": {
                    "$ref": "#/definitions/openai.ChatMessagePartType"
                }
            }
        },
        "openai.ChatMessagePartType": {
            "type": "string",
            "enum": [
                "text",
                "image_url"
            ],
            "x-enum-varnames": [
                "ChatMessagePartTypeText",
                "ChatMessagePartTypeImageURL"
            ]
        },
        "openai.CompletionTokensDetails": {
            "type": "object",
            "properties": {
                "accepted_prediction_tokens": {
                    "type": "integer"
                },
                "audio_tokens": {
                    "type": "integer"
                },
                "reasoning_tokens": {
                    "type": "integer"
                },
                "rejected_prediction_tokens": {
                    "type": "integer"
                }
            }
        },
        "openai.ContentFilterResults": {
            "type": "object",
            "properties": {
                "hate": {
                    "$ref": "#/definitions/openai.Hate"
                },
                "jailbreak": {
                    "$ref": "#/definitions/openai.JailBreak"
                },
                "profanity": {
                    "$ref": "#/definitions/openai.Profanity"
                },
                "self_harm": {
                    "$ref": "#/definitions/openai.SelfHarm"
                },
                "sexual": {
                    "$ref": "#/definitions/openai.Sexual"
                },
                "violence": {
                    "$ref": "#/definitions/openai.Violence"
                }
            }
        },
        "openai.FinishReason": {
            "type": "string",
            "enum": [
                "stop",
                "length",
                "function_call",
                "tool_calls",
                "content_filter",
                "null"
            ],
            "x-enum-varnames": [
                "FinishReasonStop",
                "FinishReasonLength",
                "FinishReasonFunctionCall",
                "FinishReasonToolCalls",
                "FinishReasonContentFilter",
                "FinishReasonNull"
            ]
        },
        "openai.FunctionCall": {
            "type": "object",
            "properties": {
                "arguments": {
                    "description": "call function with arguments in JSON format",
                    "type": "string"
                },
                "name": {
                    "type": "string"
                }
            }
        },
        "openai.FunctionDefinition": {
            "type": "object",
            "properties": {
                "description": {
                    "type": "string"
                },
                "name": {
                    "type": "string"
                },
                "parameters": {
                    "description": "Parameters is an object describing the function.\nYou can pass json.RawMessage to describe the schema,\nor you can pass in a struct which serializes to the proper JSON schema.\nThe jsonschema package is provided for convenience, but you should\nconsider another specialized library if you require more complex schemas."
                },
                "strict": {
                    "type": "boolean"
                }
            }
        },
        "openai.Hate": {
            "type": "object",
            "properties": {
                "filtered": {
                    "type": "boolean"
                },
                "severity": {
                    "type": "string"
                }
            }
        },
        "openai.ImageURLDetail": {
            "type": "string",
            "enum": [
                "high",
                "low",
                "auto"
            ],
            "x-enum-varnames": [
                "ImageURLDetailHigh",
                "ImageURLDetailLow",
                "ImageURLDetailAuto"
            ]
        },
        "openai.JailBreak": {
            "type": "object",
            "properties": {
                "detected": {
                    "type": "boolean"
                },
                "filtered": {
                    "type": "boolean"
                }
            }
        },
        "openai.LogProb": {
            "type": "object",
            "properties": {
                "bytes": {
                    "description": "Omitting the field if it is null",
                    "type": "array",
                    "items": {
                        "type": "integer"
                    }
                },
                "logprob": {
                    "type": "number"
                },
                "token": {
                    "type": "string"
                },
                "top_logprobs": {
                    "description": "TopLogProbs is a list of the most likely tokens and their log probability, at this token position.\nIn rare cases, there may be fewer than the number of requested top_logprobs returned.",
                    "type": "array",
                    "items": {
                        "$ref": "#/definitions/openai.TopLogProbs"
                    }
                }
            }
        },
        "openai.LogProbs": {
            "type": "object",
            "properties": {
                "content": {
                    "description": "Content is a list of message content tokens with log probability information.",
                    "type": "array",
                    "items": {
                        "$ref": "#/definitions/openai.LogProb"
                    }
                }
            }
        },
        "openai.Prediction": {
            "type": "object",
            "properties": {
                "content": {
                    "type": "string"
                },
                "type": {
                    "type": "string"
                }
            }
        },
        "openai.Profanity": {
            "type": "object",
            "properties": {
                "detected": {
                    "type": "boolean"
                },
                "filtered": {
                    "type": "boolean"
                }
            }
        },
        "openai.PromptTokensDetails": {
            "type": "object",
            "properties": {
                "audio_tokens": {
                    "type": "integer"
                },
                "cached_tokens": {
                    "type": "integer"
                }
            }
        },
        "openai.SelfHarm": {
            "type": "object",
            "properties": {
                "filtered": {
                    "type": "boolean"
                },
                "severity": {
                    "type": "string"
                }
            }
        },
        "openai.ServiceTier": {
            "type": "string",
            "enum": [
                "auto",
                "default",
                "flex",
                "priority"
            ],
            "x-enum-varnames": [
                "ServiceTierAuto",
                "ServiceTierDefault",
                "ServiceTierFlex",
                "ServiceTierPriority"
            ]
        },
        "openai.Sexual": {
            "type": "object",
            "properties": {
                "filtered": {
                    "type": "boolean"
                },
                "severity": {
                    "type": "string"
                }
            }
        },
        "openai.StreamOptions": {
            "type": "object",
            "properties": {
                "include_usage": {
                    "description": "If set, an additional chunk will be streamed before the data: [DONE] message.\nThe usage field on this chunk shows the token usage statistics for the entire request,\nand the choices field will always be an empty array.\nAll other chunks will also include a usage field, but with a null value.",
                    "type": "boolean"
                }
            }
        },
        "openai.Tool": {
            "type": "object",
            "properties": {
                "function": {
                    "$ref": "#/definitions/openai.FunctionDefinition"
                },
                "type": {
                    "$ref": "#/definitions/openai.ToolType"
                }
            }
        },
        "openai.ToolCall": {
            "type": "object",
            "properties": {
                "function": {
                    "$ref": "#/definitions/openai.FunctionCall"
                },
                "id": {
                    "type": "string"
                },
                "index": {
                    "description": "Index is not nil only in chat completion chunk object",
                    "type": "integer"
                },
                "type": {
                    "$ref": "#/definitions/openai.ToolType"
                }
            }
        },
        "openai.ToolType": {
            "type": "string",
            "enum": [
                "function"
            ],
            "x-enum-varnames": [
                "ToolTypeFunction"
            ]
        },
        "openai.TopLogProbs": {
            "type": "object",
            "properties": {
                "bytes": {
                    "type": "array",
                    "items": {
                        "type": "integer"
                    }
                },
                "logprob": {
                    "type": "number"
                },
                "token": {
                    "type": "string"
                }
            }
        },
        "openai.Usage": {
            "type": "object",
            "properties": {
                "completion_tokens": {
                    "type": "integer"
                },
                "completion_tokens_details": {
                    "$ref": "#/definitions/openai.CompletionTokensDetails"
                },
                "prompt_tokens": {
                    "type": "integer"
                },
                "prompt_tokens_details": {
                    "$ref": "#/definitions/openai.PromptTokensDetails"
                },
                "total_tokens": {
                    "type": "integer"
                }
            }
        },
        "openai.Violence": {
            "type": "object",
            "properties": {
                "filtered": {
                    "type": "boolean"
                },
                "severity": {
                    "type": "string"
                }
            }
        }
    }
}`

// SwaggerInfo holds exported Swagger Info so clients can modify it
var SwaggerInfo = &swag.Spec{
	Version:          "",
	Host:             "",
	BasePath:         "",
	Schemes:          []string{},
	Title:            "",
	Description:      "",
	InfoInstanceName: "swagger",
	SwaggerTemplate:  docTemplate,
	LeftDelim:        "{{",
	RightDelim:       "}}",
}

func init() {
	swag.Register(SwaggerInfo.InstanceName(), SwaggerInfo)
}
